{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fa7c42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b9ced1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "winner_list = pd.DataFrame({'file_path':pd.read_csv(r'..\\Paper\\Winner_path.csv').iloc[:,1]})\n",
    "loser_list = pd.DataFrame({'file_path':pd.read_csv(r'..\\Paper\\Loser_path.csv').iloc[:,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9532385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_path = '..\\Paper\\Winner\\\\'\n",
    "loser_path = '..\\Paper\\Loser\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b06f363b",
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_list['file_path'] = winner_list['file_path'].apply(lambda path:os.path.join(winner_path, path))\n",
    "loser_list['file_path'] = loser_list['file_path'].apply(lambda path:os.path.join(loser_path, path))\n",
    "winner_list['decision'] = 1\n",
    "loser_list['decision'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1db2a2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([winner_list,loser_list]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cda028c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = []\n",
    "missing = []\n",
    "for i in range(len(df)):\n",
    "    img = cv2.imread(df['file_path'].loc[i])\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, (323, 172))\n",
    "        img_list.append(img)\n",
    "X = np.concatenate(img_list, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f155094",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.applications import VGG16, DenseNet121,VGG19\n",
    "from tensorflow.keras.applications import MobileNetV3Small, MobileNetV3Large,ResNet152V2\n",
    "from keras.callbacks import EarlyStopping,LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e35ffb7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = X.reshape(len(df), 323,172,3)/255\n",
    "X_noise = X + np.random.normal(loc=0, scale=0.05, size=X.shape)\n",
    "X_noise = np.clip(X_noise, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f8338bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['decision']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77856ea7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_noise,y,random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbf2aef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12a9540b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "29089792/29084464 [==============================] - 27s 1us/step\n",
      "29097984/29084464 [==============================] - 27s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# Application\n",
    "input_shape=(323, 172, 3)\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "Application = DenseNet121(weights='imagenet', include_top=False)\n",
    "for layer in Application.layers:\n",
    "    layer.trainable = False    \n",
    "app_model = Application(inputs)\n",
    "\n",
    "# Flatten\n",
    "x = Dropout(0.2)(app_model)\n",
    "x = Flatten()(app_model)\n",
    "# Output\n",
    "output = Dense(1, activation='sigmoid', name='decision') (x)\n",
    "\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94a1e05d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 323, 172, 3)]     0         \n",
      "_________________________________________________________________\n",
      "densenet121 (Functional)     (None, None, None, 1024)  7037504   \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 51200)             0         \n",
      "_________________________________________________________________\n",
      "decision (Dense)             (None, 1)                 51201     \n",
      "=================================================================\n",
      "Total params: 7,088,705\n",
      "Trainable params: 51,201\n",
      "Non-trainable params: 7,037,504\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0edd182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed55057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.001\n",
    "def lr_schedule(epoch):\n",
    "    decay_rate = 0.8\n",
    "    decay_step = 5  # Adjust this as needed\n",
    "    return initial_learning_rate * decay_rate ** (epoch // decay_step)\n",
    "optimizer = Adam(learning_rate=initial_learning_rate)\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f4b7de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy',\n",
    "             optimizer = optimizer,\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79667531",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "11/11 [==============================] - 18s 771ms/step - loss: 1.1494 - accuracy: 0.5698 - val_loss: 0.7406 - val_accuracy: 0.5641\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 0.5090 - accuracy: 0.7521 - val_loss: 0.5499 - val_accuracy: 0.7179\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 0.4080 - accuracy: 0.7778 - val_loss: 0.5002 - val_accuracy: 0.7521\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 0.3075 - accuracy: 0.8661 - val_loss: 0.4976 - val_accuracy: 0.7778\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 0.2439 - accuracy: 0.9202 - val_loss: 0.4466 - val_accuracy: 0.8120\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 0.2048 - accuracy: 0.9487 - val_loss: 0.5589 - val_accuracy: 0.7350\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 0.1664 - accuracy: 0.9487 - val_loss: 0.4085 - val_accuracy: 0.8547\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 0.1357 - accuracy: 0.9801 - val_loss: 0.4446 - val_accuracy: 0.8034\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 1s 132ms/step - loss: 0.1228 - accuracy: 0.9886 - val_loss: 0.4384 - val_accuracy: 0.8120\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 1s 132ms/step - loss: 0.1084 - accuracy: 0.9886 - val_loss: 0.3956 - val_accuracy: 0.8632\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 0.1052 - accuracy: 0.9972 - val_loss: 0.3943 - val_accuracy: 0.8547\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 0.0996 - accuracy: 0.9915 - val_loss: 0.4085 - val_accuracy: 0.8462\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 0.0930 - accuracy: 0.9943 - val_loss: 0.4188 - val_accuracy: 0.8291\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 0.0822 - accuracy: 0.9943 - val_loss: 0.3940 - val_accuracy: 0.8718\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 0.0795 - accuracy: 0.9943 - val_loss: 0.4353 - val_accuracy: 0.8205\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 0.0706 - accuracy: 0.9943 - val_loss: 0.4534 - val_accuracy: 0.8034\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 0.0648 - accuracy: 1.0000 - val_loss: 0.3874 - val_accuracy: 0.8547\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 0.0618 - accuracy: 0.9972 - val_loss: 0.3959 - val_accuracy: 0.8718\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 0.0577 - accuracy: 1.0000 - val_loss: 0.4087 - val_accuracy: 0.8462\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 0.0544 - accuracy: 1.0000 - val_loss: 0.3852 - val_accuracy: 0.8718\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 0.0548 - accuracy: 1.0000 - val_loss: 0.4012 - val_accuracy: 0.8632\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 0.0524 - accuracy: 1.0000 - val_loss: 0.4640 - val_accuracy: 0.8034\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 1s 132ms/step - loss: 0.0507 - accuracy: 1.0000 - val_loss: 0.3919 - val_accuracy: 0.8718\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 0.0467 - accuracy: 1.0000 - val_loss: 0.4058 - val_accuracy: 0.8632\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 0.0462 - accuracy: 1.0000 - val_loss: 0.4335 - val_accuracy: 0.8291\n",
      "Epoch 26/40\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 0.0447 - accuracy: 1.0000 - val_loss: 0.4024 - val_accuracy: 0.8632\n",
      "Epoch 27/40\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 0.0430 - accuracy: 1.0000 - val_loss: 0.4017 - val_accuracy: 0.8632\n",
      "Epoch 28/40\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 0.0428 - accuracy: 1.0000 - val_loss: 0.4445 - val_accuracy: 0.8205\n",
      "Epoch 29/40\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 0.0415 - accuracy: 1.0000 - val_loss: 0.3960 - val_accuracy: 0.8718\n",
      "Epoch 30/40\n",
      "11/11 [==============================] - 1s 134ms/step - loss: 0.0399 - accuracy: 1.0000 - val_loss: 0.3966 - val_accuracy: 0.8632\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00030: early stopping\n"
     ]
    }
   ],
   "source": [
    "train = model.fit(X_train, y_train, validation_data = (X_val,y_val),epochs = 40,shuffle=True,callbacks=[lr_scheduler,early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e90d8989",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['history_V2.joblib']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('model_V2.h5')\n",
    "\n",
    "# Save the training history\n",
    "joblib.dump(train.history, 'history_V2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdf5d96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
